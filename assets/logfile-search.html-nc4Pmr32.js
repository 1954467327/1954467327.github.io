import{_ as n,c as a,a as e,o as l}from"./app-svGwMmXC.js";const i={};function p(t,s){return l(),a("div",null,[...s[0]||(s[0]=[e(`<h1 id="linux日志排查命令" tabindex="-1"><a class="header-anchor" href="#linux日志排查命令"><span>Linux日志排查命令</span></a></h1><p>由于日志内容的复查情况以及某些模块存在日志量巨大，需要实时复现才好查看日志，可以通过此文章命令排查</p><h2 id="一、tail" tabindex="-1"><a class="header-anchor" href="#一、tail"><span>一、tail</span></a></h2><h3 id="_1-服务启动日志监控" tabindex="-1"><a class="header-anchor" href="#_1-服务启动日志监控"><span>1. 服务启动日志监控</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># -f (follow)：实时追加显示文件尾部内容 -n 末尾多少行</span></span>
<span class="line"><span class="token function">tail</span> <span class="token parameter variable">-f</span> logs/application.log</span>
<span class="line"><span class="token comment"># 合并命令</span></span>
<span class="line"><span class="token function">tail</span> <span class="token parameter variable">-200f</span> logs/application.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="二、less" tabindex="-1"><a class="header-anchor" href="#二、less"><span>二、less</span></a></h2><h3 id="_1-按需加载查看" tabindex="-1"><a class="header-anchor" href="#_1-按需加载查看"><span>1.按需加载查看</span></a></h3><p>如果需要查看之前的日志，推荐使用 less。不同于 vim 会一次性加载整个文件占用大量内存，less 是按需加载，打开几个 G 的文件也极其流畅，且支持向后回溯，以下命令vi进入编辑器也支持。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token function">less</span> logs/application.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>进入界面后的操作流：</p><ol><li>Shift + G 先跳到日志最末尾（因为报错通常发生在最近）。</li><li>?ORD12345678 输入问号+订单号，向上反向搜索。</li><li>n：如果当前这行不是关键信息，按 n 继续向上找上一次出现的位置</li><li>Shift + n 查看下一行</li><li>Shift + F 如果看着看着，日志又更新了，按这个组合键可以让 less 进入类似 tail -f 的实时滚动模式；按 Ctrl + C 退回浏览模式。</li><li>q 退出</li></ol><h2 id="三、grep" tabindex="-1"><a class="header-anchor" href="#三、grep"><span>三、grep</span></a></h2><h3 id="_1-查找指定关键字的前后20行" tabindex="-1"><a class="header-anchor" href="#_1-查找指定关键字的前后20行"><span>1. 查找指定关键字的前后20行</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># 搜索异常关键字，并显示该行 &quot;前后各 20 行&quot;</span></span>
<span class="line"><span class="token function">grep</span> <span class="token parameter variable">-C</span> <span class="token number">20</span> <span class="token string">&quot;Exception&quot;</span> application.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-全链路追踪-traceid" tabindex="-1"><a class="header-anchor" href="#_2-全链路追踪-traceid"><span>2. 全链路追踪 TraceId</span></a></h3><p>微服务我们通常会通过 TraceId 串联请求。日志文件可能发生了滚动（Rolling），变成了 app.log、app.log.1、app.log.2。</p><p>我们需要在所有日志文件中搜索同一个 TraceId。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># 搜索当前目录下所有以 app.log 开头的文件</span></span>
<span class="line"><span class="token function">grep</span> <span class="token string">&quot;TraceId-20251219001&quot;</span> logs/app.log*</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-统计异常频次" tabindex="-1"><a class="header-anchor" href="#_3-统计异常频次"><span>3. 统计异常频次</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># -c (count)：只统计匹配的行数</span></span>
<span class="line"><span class="token function">grep</span> <span class="token parameter variable">-c</span> <span class="token string">&quot;RedisConnectionException&quot;</span> logs/application.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-排除干扰噪音" tabindex="-1"><a class="header-anchor" href="#_4-排除干扰噪音"><span>4. 排除干扰噪音</span></a></h3><p>排查问题时，日志里充斥着大量无关的 INFO 心跳日志或健康检查日志，严重干扰视线。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># -v (invert)：显示不包含 &quot;HealthCheck&quot; 的所有行</span></span>
<span class="line"><span class="token function">grep</span> <span class="token parameter variable">-v</span> <span class="token string">&quot;HealthCheck&quot;</span> logs/application.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="四、sed" tabindex="-1"><a class="header-anchor" href="#四、sed"><span>四、sed</span></a></h2><h3 id="_1-导出事故时间窗口的日志" tabindex="-1"><a class="header-anchor" href="#_1-导出事故时间窗口的日志"><span>1. 导出事故时间窗口的日志</span></a></h3><p>有时候日志非常大，例如有 10GB，grep 搜出来的内容依然过多。如果我们明确知道生产事故发生在 14:00 到 14:05 之间，该怎么办？</p><p>下载整个日志不现实，sed 可以帮我们把这段时间的日志单独切出来，保存成一个小文件慢慢分析。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># 语法：sed -n &#39;/开始时间/,/结束时间/p&#39; 源文件 &gt; 目标文件</span></span>
<span class="line"><span class="token comment">#       sed -n &#39;/pattern1/,/pattern2/p&#39; filename</span></span>
<span class="line"><span class="token comment"># 注意：时间格式必须和日志里的格式完全一致</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 提取从 00:01:00 到 00:02:00 的日志（同一天）</span></span>
<span class="line"><span class="token function">sed</span> <span class="token parameter variable">-n</span> <span class="token string">&#39;/^2026-01-22 00:01:/,/^2026-01-22 00:02:/p&#39;</span> uniweb-global-setting.log <span class="token operator">&gt;</span> error_segment.log</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 或者更精确的时间范围（包含毫秒）</span></span>
<span class="line"><span class="token function">sed</span> <span class="token parameter variable">-n</span> <span class="token string">&#39;/^2026-01-22 00:01:00\\.003/,/^2026-01-22 00:02:00\\.000/p&#39;</span> uniweb-global-setting.log <span class="token operator">&gt;</span> error_segment.log</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 提取从 1月21日 到 1月22日的日志</span></span>
<span class="line"><span class="token function">sed</span> <span class="token parameter variable">-n</span> <span class="token string">&#39;/^2026-01-21/,/^2026-01-22/p&#39;</span> uniweb-global-setting.log <span class="token operator">&gt;</span> multi_day_logs.log</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="五、-awk" tabindex="-1"><a class="header-anchor" href="#五、-awk"><span>五、 Awk</span></a></h2><p>awk 擅长处理列数据，对于格式规范的日志，如 Nginx 访问日志、Apache 日志，它可以直接在服务器上生成简报。</p><h3 id="_1-遭到攻击-查找恶意-ip" tabindex="-1"><a class="header-anchor" href="#_1-遭到攻击-查找恶意-ip"><span>1. 遭到攻击，查找恶意 IP</span></a></h3><p>服务突然报警 CPU 飙升，怀疑遭到 CC 攻击或爬虫抓取，我们需要分析 Nginx 日志，找出访问量最高的 IP。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># 1. awk &#39;{print $1}&#39;：提取第一列（IP）</span></span>
<span class="line"><span class="token comment"># 2. sort：排序，把相同的 IP 排在一起</span></span>
<span class="line"><span class="token comment"># 3. uniq -c：去重并统计每个 IP 出现的次数</span></span>
<span class="line"><span class="token comment"># 4. sort -nr：按次数(n)倒序(r)排列</span></span>
<span class="line"><span class="token comment"># 5. head -n 10：取前 10 名</span></span>
<span class="line"></span>
<span class="line"><span class="token function">awk</span> <span class="token string">&#39;{print $1}&#39;</span> access.log <span class="token operator">|</span> <span class="token function">sort</span> <span class="token operator">|</span> <span class="token function">uniq</span> <span class="token parameter variable">-c</span> <span class="token operator">|</span> <span class="token function">sort</span> <span class="token parameter variable">-nr</span> <span class="token operator">|</span> <span class="token function">head</span> <span class="token parameter variable">-n</span> <span class="token number">10</span></span>
<span class="line"></span>
<span class="line"><span class="token punctuation">[</span>root@LV7000-CE791A logs<span class="token punctuation">]</span><span class="token comment"># awk &#39;{print $1}&#39; access.log | sort | uniq -c | sort -nr | head -n 10</span></span>
<span class="line">   <span class="token number">9315</span> <span class="token number">10.20</span>.3.2</span>
<span class="line">   <span class="token number">4880</span> <span class="token number">10.20</span>.13.135</span>
<span class="line">   <span class="token number">3680</span> <span class="token number">10.20</span>.13.168</span>
<span class="line">   <span class="token number">3534</span> <span class="token number">10.20</span>.13.97</span>
<span class="line">   <span class="token number">1290</span> <span class="token number">10.20</span>.13.122</span>
<span class="line">    <span class="token number">656</span> <span class="token number">127.0</span>.0.1</span>
<span class="line">    <span class="token number">398</span> <span class="token number">10.20</span>.13.174</span>
<span class="line">    <span class="token number">223</span> <span class="token number">10.20</span>.24.106</span>
<span class="line">     <span class="token number">12</span> <span class="token number">10.19</span>.31.178</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-找出响应最慢的接口" tabindex="-1"><a class="header-anchor" href="#_2-找出响应最慢的接口"><span>2. 找出响应最慢的接口</span></a></h3><p>Nginx 日志中通常记录了响应时间，假设在最后一列，我们想把响应时间超过 1 秒的请求找出来。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh"><pre><code><span class="line"><span class="token comment"># $NF 代表最后一列,打印第12个字段和最后一个字段，用空格分隔</span></span>
<span class="line"><span class="token comment"># 打印所有响应时间大于 1 秒的 URL（假设 URL 在第 12 列）</span></span>
<span class="line"><span class="token function">awk</span> <span class="token string">&#39;$12 &gt; 1.000 {print $12, $NF}&#39;</span> access.log</span>
<span class="line"></span>
<span class="line"><span class="token punctuation">[</span>root@LV7000-CE791A logs<span class="token punctuation">]</span><span class="token comment"># awk &#39;$12 &gt; 6000000 {print $12, $NF}&#39; access.log</span></span>
<span class="line"><span class="token number">6917288</span> <span class="token string">&quot;https://10.19.31.166:8443/assets/index-300c691a.css&quot;</span></span>
<span class="line">HTTP/1.1<span class="token string">&quot; &quot;</span>-<span class="token string">&quot;</span>
<span class="line">6917288 &quot;</span>https://10.19.31.166:8443/uni-app/assets/index-95ded47c.css<span class="token string">&quot;</span>
<span class="line">6917288 &quot;</span>https://10.19.31.166:8443/uni-app/assets/index-95ded47c.css&quot;</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,36)])])}const r=n(i,[["render",p]]),o=JSON.parse('{"path":"/posts/logfile-search.html","title":"Linux日志排查命令","lang":"zh-CN","frontmatter":{"lang":"zh-CN","title":"Linux日志排查命令","description":"由于日志内容的复查情况以及某些模块存在日志量巨大，需要实时复现才好查看日志","date":"2026-01-21T00:00:00.000Z","category":["Linux"],"tag":["日志排查"]},"headers":[{"level":2,"title":"一、tail","slug":"一、tail","link":"#一、tail","children":[{"level":3,"title":"1. 服务启动日志监控","slug":"_1-服务启动日志监控","link":"#_1-服务启动日志监控","children":[]}]},{"level":2,"title":"二、less","slug":"二、less","link":"#二、less","children":[{"level":3,"title":"1.按需加载查看","slug":"_1-按需加载查看","link":"#_1-按需加载查看","children":[]}]},{"level":2,"title":"三、grep","slug":"三、grep","link":"#三、grep","children":[{"level":3,"title":"1. 查找指定关键字的前后20行","slug":"_1-查找指定关键字的前后20行","link":"#_1-查找指定关键字的前后20行","children":[]},{"level":3,"title":"2. 全链路追踪 TraceId","slug":"_2-全链路追踪-traceid","link":"#_2-全链路追踪-traceid","children":[]},{"level":3,"title":"3. 统计异常频次","slug":"_3-统计异常频次","link":"#_3-统计异常频次","children":[]},{"level":3,"title":"4. 排除干扰噪音","slug":"_4-排除干扰噪音","link":"#_4-排除干扰噪音","children":[]}]},{"level":2,"title":"四、sed","slug":"四、sed","link":"#四、sed","children":[{"level":3,"title":"1. 导出事故时间窗口的日志","slug":"_1-导出事故时间窗口的日志","link":"#_1-导出事故时间窗口的日志","children":[]}]},{"level":2,"title":"五、 Awk","slug":"五、-awk","link":"#五、-awk","children":[{"level":3,"title":"1. 遭到攻击，查找恶意 IP","slug":"_1-遭到攻击-查找恶意-ip","link":"#_1-遭到攻击-查找恶意-ip","children":[]},{"level":3,"title":"2. 找出响应最慢的接口","slug":"_2-找出响应最慢的接口","link":"#_2-找出响应最慢的接口","children":[]}]}],"git":{"updatedTime":1769072982000,"contributors":[{"name":"litong","username":"litong","email":"litong@leagsoft.com","commits":1,"url":"https://github.com/litong"}],"changelog":[{"hash":"e0d7c5d1773a847394df4ff7bb7d67c52348ac84","time":1769072982000,"email":"litong@leagsoft.com","author":"litong","message":"新增：更新支持特殊字符"}]},"filePathRelative":"posts/logfile-search.md","excerpt":"\\n<p>由于日志内容的复查情况以及某些模块存在日志量巨大，需要实时复现才好查看日志，可以通过此文章命令排查</p>\\n<h2>一、tail</h2>\\n<h3>1. 服务启动日志监控</h3>\\n<div class=\\"language-bash line-numbers-mode\\" data-highlighter=\\"prismjs\\" data-ext=\\"sh\\"><pre><code><span class=\\"line\\"><span class=\\"token comment\\"># -f (follow)：实时追加显示文件尾部内容 -n 末尾多少行</span></span>\\n<span class=\\"line\\"><span class=\\"token function\\">tail</span> <span class=\\"token parameter variable\\">-f</span> logs/application.log</span>\\n<span class=\\"line\\"><span class=\\"token comment\\"># 合并命令</span></span>\\n<span class=\\"line\\"><span class=\\"token function\\">tail</span> <span class=\\"token parameter variable\\">-200f</span> logs/application.log</span>\\n<span class=\\"line\\"></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>"}');export{r as comp,o as data};
